{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking Apart Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "For the following project, I will be using the natural language toolkit (NLTK) to breakdown Shakespeare's plays Macbeth and Hamlet. The primary purpose of this project is to demonstrate how to utilize NLTK on text documents. During this process, I will create a model to identify Shakespeare's writing style, specifically the types of words utilized in this work. This will be done by using the NLTK modules Part of Speech Tagging and Chunking. In addition to model reaction, k-means clustering will be performed on both plays. The end result is to compare model creation and clustering as methods for working with text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import io\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to C:\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "nltk.download('gutenberg')\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac = gutenberg.raw('shakespeare-macbeth.txt')\n",
    "ham = gutenberg.raw('shakespeare-hamlet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"[\\[].*?[\\]]\"\n",
    "mac = re.sub(pattern, \"\", mac)\n",
    "ham = re.sub(pattern, \"\", ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac = re.sub(r'Chapter \\d+', '', mac)\n",
    "ham = re.sub(r'Chapter \\d+', '', ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac = ' '.join(mac.split())\n",
    "ham = ' '.join(ham.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "In this process, meaningful segments from the text are extracted by breaking up the text from sentences to words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "#print(word_tokens)\n",
    "#print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Doubtfull',\n",
       "  'it',\n",
       "  'stood',\n",
       "  ',',\n",
       "  'As',\n",
       "  'two',\n",
       "  'spent',\n",
       "  'Swimmers',\n",
       "  ',',\n",
       "  'that',\n",
       "  'doe',\n",
       "  'cling',\n",
       "  'together',\n",
       "  ',',\n",
       "  'And',\n",
       "  'choake',\n",
       "  'their',\n",
       "  'Art',\n",
       "  ':',\n",
       "  'The',\n",
       "  'mercilesse',\n",
       "  'Macdonwald',\n",
       "  Ellipsis]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "macbeth_sentences\n",
    "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare',\n",
    "'1603', ']'], ['Actus', 'Primus', '.'], ...]\n",
    "macbeth_sentences[1116]\n",
    "['Double', ',', 'double', ',', 'toile', 'and', 'trouble', ';',\n",
    "'Fire', 'burne', ',', 'and', 'Cauldron', 'bubble']\n",
    "longest_len = max(len(s) for s in macbeth_sentences)\n",
    "[s for s in macbeth_sentences if len(s) == longest_len]\n",
    "[['Doubtfull', 'it', 'stood', ',', 'As', 'two', 'spent', 'Swimmers', ',', 'that',\n",
    "'doe', 'cling', 'together', ',', 'And', 'choake', 'their', 'Art', ':', 'The',\n",
    "'mercilesse', 'Macdonwald', ...]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "The following process eliminates useless phrases found commonly within the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(mac)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging\n",
    "\n",
    "This method is utilized to label the words in each sentence. The labels indicate whether the word is a noun, verb, adjective, and so on. I used Shakespeare's Hamlet as well as Macbeth to create a model, tokenize, and then create a function that will tag all the parts of speech for each sentence. This model displays the type of words commonly found in Shakespeare's work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "sample_text = gutenberg.raw('shakespeare-macbeth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[', 'IN'), ('The', 'DT'), ('Tragedie', 'NNP'), ('of', 'IN'), ('Macbeth', 'NNP'), ('by', 'IN'), ('William', 'NNP'), ('Shakespeare', 'NNP'), ('1603', 'CD'), (']', 'NNP'), ('Actus', 'NNP'), ('Primus', 'NNP'), ('.', '.')]\n",
      "[('Scoena', 'NNP'), ('Prima', 'NNP'), ('.', '.')]\n",
      "[('Thunder', 'NN'), ('and', 'CC'), ('Lightning', 'NNP'), ('.', '.')]\n",
      "[('Enter', 'NNP'), ('three', 'CD'), ('Witches', 'NNP'), ('.', '.')]\n",
      "[('1', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "\n",
    "After establishing the parts of speech, I created groups based of the commonly found tags. I mainly focused on group together words that were coordinating conjuntions, cardinal digits, proper nouns, or nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunkGram = r\"\"\"Chunk: {<CC.?>*<CD.?>*<NNP>+<NN>?}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            chunked.draw()\n",
    "   \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "Below is K-means clustering, first for Macbeth and second for Hamlet. Both will breakdown into two clusters. The hard-clustering method will indicate which words group together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actus Primus.\n",
      "Scoena Prima.\n",
      "Thunder and Lightning.\n",
      "Enter three Witches.\n",
      "1.\n",
      "When shall we three meet againe?\n",
      "In Thunder, Lightning, or in Raine?\n",
      "2.\n",
      "When the Hurley-burley's done, When the Battaile's lost, and wonne 3.\n",
      "That will be ere the set of Sunne 1.\n",
      "Where the place?\n",
      "2.\n",
      "Vpon the Heath 3.\n",
      "There to meet with Macbeth 1.\n",
      "I come, Gray-Malkin All.\n",
      "Padock calls anon: faire is foule, and foule is faire, Houer through the fogge and filthie ayre.\n",
      "Exeunt.\n",
      "Scena Secunda.\n",
      "Alarum within.\n",
      "Enter King Malcome, Donalbaine, Lenox, with attendants, meeting a bleeding Captaine.\n",
      "King.\n",
      "What bloody man is that?\n",
      "he can report, As seemeth by his plight, of the Reuolt The newest state Mal.\n",
      "This is the Serieant, Who like a good and hardie Souldier fought 'Gainst my Captiuitie: Haile braue friend; Say to the King, the knowledge of the Broyle, As thou didst leaue it Cap.\n",
      "Doubtfull it stood, As two spent Swimmers, that doe cling together, And choake their Art: The mercilesse Macdonwald (Worthie to be a Rebell, for to that The multiplying Villanies of Nature Doe swarme vpon him) from the Westerne Isles Of Kernes and Gallowgrosses is supply'd, And Fortune on his damned Quarry smiling, Shew'd like a Rebells Whore: but all's too weake: For braue Macbeth (well hee deserues that Name) Disdayning Fortune, with his brandisht Steele, Which smoak'd with bloody execution (Like Valours Minion) caru'd out his passage, Till hee fac'd the Slaue: Which neu'r shooke hands, nor bad farwell to him, Till he vnseam'd him from the Naue toth' Chops, And fix'd his Head vpon our Battlements King.\n",
      "O valiant Cousin, worthy Gentleman Cap.\n",
      "As whence the Sunne 'gins his reflection, Shipwracking Stormes, and direfull Thunders: So from that Spring, whence comfort seem'd to come, Discomfort swells: Marke King of Scotland, marke, No sooner Iustice had, with Valour arm'd, Compell'd these skipping Kernes to trust their heeles, But the Norweyan Lord, surueying vantage, With furbusht Armes, and new supplyes of men, Began a fresh assault King.\n",
      "Dismay'd not this our Captaines, Macbeth and Banquoh?\n",
      "Cap.\n",
      "Yes, as Sparrowes, Eagles; Or the Hare, the Lyon: If I say sooth, I must report they were As Cannons ouer-charg'd with double Cracks, So they doubly redoubled stroakes vpon the Foe: Except they meant to bathe in reeking Wounds, Or memorize another Golgotha, I cannot tell: but I am faint, My Gashes cry for helpe King.\n",
      "So well thy words become thee, as thy wounds, They smack of Honor both: Goe get him Surgeons.\n",
      "Enter Rosse and Angus.\n",
      "Who comes here?\n",
      "Mal.\n",
      "The worthy Thane of Rosse Lenox.\n",
      "What a haste lookes through his eyes?\n",
      "So should he looke, that seemes to speake things strange Rosse.\n",
      "God saue the King King.\n",
      "Whence cam'st thou, worthy Thane?\n",
      "Rosse.\n",
      "From Fiffe, great King, Where the Norweyan Banners flowt the Skie, And fanne our people cold.\n",
      "Norway himselfe, with terrible numbers, Assisted by that most disloyall Traytor, The Thane of Cawdor, began a dismall Conflict, Till that Bellona's Bridegroome, lapt in proofe, Confronted him with selfe-comparisons, Point against Point, rebellious Arme 'gainst Arme, Curbing his lauish spirit: and to conclude, The Victorie fell on vs King.\n",
      "Great happinesse Rosse.\n",
      "That now Sweno, the Norwayes King, Craues composition: Nor would we deigne him buriall of his men, Till he disbursed, at Saint Colmes ynch, Ten thousand Dollars, to our generall vse King.\n",
      "No more that Thane of Cawdor shall deceiue Our Bosome interest: Goe pronounce his present death, And with his former Title greet Macbeth Rosse.\n",
      "Ile see it done King.\n",
      "What he hath lost, Noble Macbeth hath wonne.\n",
      "Exeunt.\n",
      "Scena Tertia.\n",
      "Thunder.\n",
      "Enter the three Witches.\n",
      "1.\n",
      "Where hast thou beene, Sister?\n",
      "2.\n",
      "Killing Swine 3.\n",
      "Sister, where thou?\n",
      "1.\n",
      "A Saylors Wife had Chestnuts in her Lappe, And mouncht, & mouncht, and mouncht: Giue me, quoth I. Aroynt thee, Witch, the rumpe-fed Ronyon cryes.\n",
      "Her Husband's to Aleppo gone, Master o'th' Tiger: But in a Syue Ile thither sayle, And like a Rat without a tayle, Ile doe, Ile doe, and Ile doe 2.\n",
      "Ile giue thee a Winde 1.\n",
      "Th'art kinde 3.\n",
      "And I another 1.\n",
      "I my selfe haue all the other, And the very Ports they blow, All the Quarters that they know, I'th' Ship-mans Card.\n",
      "Ile dreyne him drie as Hay: Sleepe shall neyther Night nor Day Hang vpon his Pent-house Lid: He shall liue a man forbid: Wearie Seu'nights, nine times nine, Shall he dwindle, peake, and pine: Though his Barke cannot be lost, Yet it shall be Tempest-tost.\n",
      "Looke what I haue 2.\n",
      "Shew me, shew me 1.\n",
      "Here I haue a Pilots Thumbe, Wrackt, as homeward he did come.\n",
      "Drum within.\n",
      "3.\n",
      "A Drumme, a Drumme: Macbeth doth come All.\n",
      "The weyward Sisters, hand in hand, Posters of the Sea and Land, Thus doe goe, about, about, Thrice to thine, and thrice to mine, And thrice againe, to make vp nine.\n",
      "Peace, the Charme's wound vp.\n",
      "Enter Macbeth and Banquo.\n",
      "Macb.\n",
      "So foule and faire a day I haue not seene Banquo.\n",
      "How farre is't call'd to Soris?\n",
      "What are these, So wither'd, and so wilde in their attyre, That looke not like th' Inhabitants o'th' Earth, And yet are on't?\n",
      "Liue you, or are you aught That man may question?\n",
      "you seeme to vnderstand me, By each at once her choppie finger laying Vpon her skinnie Lips: you should be Women, And yet your Beards forbid me to interprete That you are so Mac.\n",
      "Speake if you can: what are you?\n",
      "1.\n",
      "All haile Macbeth, haile to thee Thane of Glamis 2.\n",
      "All haile Macbeth, haile to thee Thane of Cawdor 3.\n",
      "All haile Macbeth, that shalt be King hereafter Banq.\n",
      "Good Sir, why doe you start, and seeme to feare Things that doe sound so faire?\n",
      "i'th' name of truth Are ye fantasticall, or that indeed Which outwardly ye shew?\n",
      "My Noble Partner You greet with present Grace, and great prediction Of Noble hauing, and of Royall hope, That he seemes wrapt withall: to me you speake not.\n",
      "If you can looke into the Seedes of Time, And say, which Graine will grow, and which will not, Speake then to me, who neyther begge, nor feare Your fauors, nor your hate 1.\n",
      "Hayle 2.\n",
      "Hayle 3.\n",
      "Hayle 1.\n",
      "Lesser than Macbeth, and greater 2.\n",
      "Not so happy, yet much happyer 3.\n",
      "Thou shalt get Kings, though thou be none: So all haile Macbeth, and Banquo 1.\n",
      "Banquo, and Macbeth, all haile Macb.\n",
      "Stay you imperfect Speakers, tell me more: By Sinells death, I know I am Thane of Glamis, But how, of Cawdor?\n",
      "the Thane of Cawdor liues A prosperous Gentleman: And to be King, Stands not within the prospect of beleefe, No more then to be Cawdor.\n",
      "Say from whence You owe this strange Intelligence, or why Vpon this blasted Heath you stop our way With such Prophetique greeting?\n",
      "Speake, I charge you.\n",
      "Witches vanish.\n"
     ]
    }
   ],
   "source": [
    "tok = sent_tokenize(mac)\n",
    "\n",
    "for x in range(100):\n",
    "    print(tok[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=2, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " haue\n",
      " thou\n",
      " wife\n",
      " king\n",
      " mal\n",
      " thee\n",
      " lenox\n",
      " scena\n",
      " thy\n",
      " shall\n",
      "Cluster 1:\n",
      " macb\n",
      " enter\n",
      " exeunt\n",
      " lady\n",
      " macd\n",
      " rosse\n",
      " macbeth\n",
      " lord\n",
      " banquo\n",
      " lenox\n",
      "\n",
      "\n",
      "Prediction\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"Actus Primus.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"Scoena Prima.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actus Primus.\n",
      "Scoena Prima.\n",
      "Enter Barnardo and Francisco two Centinels.\n",
      "Barnardo.\n",
      "Who's there?\n",
      "Fran.\n",
      "Nay answer me: Stand & vnfold your selfe Bar.\n",
      "Long liue the King Fran.\n",
      "Barnardo?\n",
      "Bar.\n",
      "He Fran.\n",
      "You come most carefully vpon your houre Bar.\n",
      "'Tis now strook twelue, get thee to bed Francisco Fran.\n",
      "For this releefe much thankes: 'Tis bitter cold, And I am sicke at heart Barn.\n",
      "Haue you had quiet Guard?\n",
      "Fran.\n",
      "Not a Mouse stirring Barn.\n",
      "Well, goodnight.\n",
      "If you do meet Horatio and Marcellus, the Riuals of my Watch, bid them make hast.\n",
      "Enter Horatio and Marcellus.\n",
      "Fran.\n",
      "I thinke I heare them.\n",
      "Stand: who's there?\n",
      "Hor.\n",
      "Friends to this ground Mar.\n",
      "And Leige-men to the Dane Fran.\n",
      "Giue you good night Mar.\n",
      "O farwel honest Soldier, who hath relieu'd you?\n",
      "Fra.\n",
      "Barnardo ha's my place: giue you goodnight.\n",
      "Exit Fran.\n",
      "Mar.\n",
      "Holla Barnardo Bar.\n",
      "Say, what is Horatio there?\n",
      "Hor.\n",
      "A peece of him Bar.\n",
      "Welcome Horatio, welcome good Marcellus Mar.\n",
      "What, ha's this thing appear'd againe to night Bar.\n",
      "I haue seene nothing Mar.\n",
      "Horatio saies, 'tis but our Fantasie, And will not let beleefe take hold of him Touching this dreaded sight, twice seene of vs, Therefore I haue intreated him along With vs, to watch the minutes of this Night, That if againe this Apparition come, He may approue our eyes, and speake to it Hor.\n",
      "Tush, tush, 'twill not appeare Bar.\n",
      "Sit downe a-while, And let vs once againe assaile your eares, That are so fortified against our Story, What we two Nights haue seene Hor.\n",
      "Well, sit we downe, And let vs heare Barnardo speake of this Barn.\n",
      "Last night of all, When yond same Starre that's Westward from the Pole Had made his course t' illume that part of Heauen Where now it burnes, Marcellus and my selfe, The Bell then beating one Mar.\n",
      "Peace, breake thee of: Enter the Ghost.\n",
      "Looke where it comes againe Barn.\n",
      "In the same figure, like the King that's dead Mar.\n",
      "Thou art a Scholler; speake to it Horatio Barn.\n",
      "Lookes it not like the King?\n",
      "Marke it Horatio Hora.\n",
      "Most like: It harrowes me with fear & wonder Barn.\n",
      "It would be spoke too Mar.\n",
      "Question it Horatio Hor.\n",
      "What art thou that vsurp'st this time of night, Together with that Faire and Warlike forme In which the Maiesty of buried Denmarke Did sometimes march: By Heauen I charge thee speake Mar.\n",
      "It is offended Barn.\n",
      "See, it stalkes away Hor.\n",
      "Stay: speake; speake: I Charge thee, speake.\n",
      "Exit the Ghost.\n",
      "Mar.\n",
      "'Tis gone, and will not answer Barn.\n",
      "How now Horatio?\n",
      "You tremble & look pale: Is not this something more then Fantasie?\n",
      "What thinke you on't?\n",
      "Hor.\n",
      "Before my God, I might not this beleeue Without the sensible and true auouch Of mine owne eyes Mar.\n",
      "Is it not like the King?\n",
      "Hor.\n",
      "As thou art to thy selfe, Such was the very Armour he had on, When th' Ambitious Norwey combatted: So frown'd he once, when in an angry parle He smot the sledded Pollax on the Ice.\n",
      "'Tis strange Mar.\n",
      "Thus twice before, and iust at this dead houre, With Martiall stalke, hath he gone by our Watch Hor.\n",
      "In what particular thought to work, I know not: But in the grosse and scope of my Opinion, This boades some strange erruption to our State Mar.\n",
      "Good now sit downe, & tell me he that knowes Why this same strict and most obseruant Watch, So nightly toyles the subiect of the Land, And why such dayly Cast of Brazon Cannon And Forraigne Mart for Implements of warre: Why such impresse of Ship-wrights, whose sore Taske Do's not diuide the Sunday from the weeke, What might be toward, that this sweaty hast Doth make the Night ioynt-Labourer with the day: Who is't that can informe me?\n",
      "Hor.\n",
      "That can I, At least the whisper goes so: Our last King, Whose Image euen but now appear'd to vs, Was (as you know) by Fortinbras of Norway, (Thereto prick'd on by a most emulate Pride) Dar'd to the Combate.\n",
      "In which, our Valiant Hamlet, (For so this side of our knowne world esteem'd him) Did slay this Fortinbras: who by a Seal'd Compact, Well ratified by Law, and Heraldrie, Did forfeite (with his life) all those his Lands Which he stood seiz'd on, to the Conqueror: Against the which, a Moity competent Was gaged by our King: which had return'd To the Inheritance of Fortinbras, Had he bin Vanquisher, as by the same Cou'nant And carriage of the Article designe, His fell to Hamlet.\n",
      "Now sir, young Fortinbras, Of vnimproued Mettle, hot and full, Hath in the skirts of Norway, heere and there, Shark'd vp a List of Landlesse Resolutes, For Foode and Diet, to some Enterprize That hath a stomacke in't: which is no other (And it doth well appeare vnto our State) But to recouer of vs by strong hand And termes Compulsatiue, those foresaid Lands So by his Father lost: and this (I take it) Is the maine Motiue of our Preparations, The Sourse of this our Watch, and the cheefe head Of this post-hast, and Romage in the Land.\n",
      "Enter Ghost againe.\n",
      "But soft, behold: Loe, where it comes againe: Ile crosse it, though it blast me.\n",
      "Stay Illusion: If thou hast any sound, or vse of Voyce, Speake to me.\n",
      "If there be any good thing to be done, That may to thee do ease, and grace to me; speak to me.\n",
      "If thou art priuy to thy Countries Fate (Which happily foreknowing may auoyd) Oh speake.\n",
      "Or, if thou hast vp-hoorded in thy life Extorted Treasure in the wombe of Earth, (For which, they say, you Spirits oft walke in death) Speake of it.\n",
      "Stay, and speake.\n",
      "Stop it Marcellus Mar.\n",
      "Shall I strike at it with my Partizan?\n",
      "Hor.\n",
      "Do, if it will not stand Barn.\n",
      "'Tis heere Hor.\n",
      "'Tis heere Mar.\n",
      "'Tis gone.\n",
      "Exit Ghost.\n",
      "We do it wrong, being so Maiesticall To offer it the shew of Violence, For it is as the Ayre, invulnerable, And our vaine blowes, malicious Mockery Barn.\n",
      "It was about to speake, when the Cocke crew Hor.\n",
      "And then it started, like a guilty thing Vpon a fearfull Summons.\n",
      "I haue heard, The Cocke that is the Trumpet to the day, Doth with his lofty and shrill-sounding Throate Awake the God of Day: and at his warning, Whether in Sea, or Fire, in Earth, or Ayre, Th' extrauagant, and erring Spirit, hyes To his Confine.\n",
      "And of the truth heerein, This present Obiect made probation Mar.\n",
      "It faded on the crowing of the Cocke.\n",
      "Some sayes, that euer 'gainst that Season comes Wherein our Sauiours Birch is celebrated, The Bird of Dawning singeth all night long: And then (they say) no Spirit can walke abroad, The nights are wholsome, then no Planets strike, No Faiery talkes, nor Witch hath power to Charme: So hallow'd, and so gracious is the time Hor.\n",
      "So haue I heard, and do in part beleeue it.\n",
      "But looke, the Morne in Russet mantle clad, Walkes o're the dew of yon high Easterne Hill, Breake we our Watch vp, and by my aduice Let vs impart what we haue seene to night Vnto yong Hamlet.\n"
     ]
    }
   ],
   "source": [
    "tok2 = sent_tokenize(ham)\n",
    "\n",
    "for x in range(100):\n",
    "    print(tok[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(tok2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=2, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " ham\n",
      " lord\n",
      " king\n",
      " enter\n",
      " haue\n",
      " ophe\n",
      " hamlet\n",
      " qu\n",
      " laer\n",
      " come\n",
      "Cluster 1:\n",
      " hor\n",
      " speake\n",
      " tis\n",
      " reueale\n",
      " puh\n",
      " strooke\n",
      " beene\n",
      " strange\n",
      " question\n",
      " follow\n",
      "\n",
      "\n",
      "Prediction\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"Actus Primus.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"Scoena Prima.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing part of speech tagging on Shakespeare plays Macbeth and Hamlet proves nouns, proper nouns, coordinating conjunctions, and cardinal digits are most commonly occurring types of words found in Shakespeare’s writings. Thus, chunking the texts based on these four tags is the most logical method for grouping them together. In comparison, K-means clustering for both pieces of literature clustered mainly nouns and proper nouns. While both techniques generate similar results, the methodology is quite different. Using part of speech tagging and chunking both texts were combined into one unit. Though K-means is an excellent unsupervised learning method for grouping data, the text files proved to be to big for the notebook to process, and had to be broken apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
